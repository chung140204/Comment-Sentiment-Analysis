{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69de3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "train = pd.read_csv('data/processed_train.csv')\n",
    "test = pd.read_csv('data/processed_test.csv')\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train['sentiment'])\n",
    "y_test = label_encoder.transform(test['sentiment'])\n",
    "\n",
    "# Vectorizer functions\n",
    "def tfidf_vectorizer():\n",
    "    vec = TfidfVectorizer(max_features=10000)\n",
    "    x_train = vec.fit_transform(train['text']).toarray()\n",
    "    x_test = vec.transform(test['text']).toarray()\n",
    "    return x_train, x_test\n",
    "\n",
    "def bog_vectorizer():\n",
    "    vec = CountVectorizer(max_features=10000)\n",
    "    x_train = vec.fit_transform(train['text']).toarray()\n",
    "    x_test = vec.transform(test['text']).toarray()\n",
    "    return x_train, x_test\n",
    "\n",
    "def binary_vectorizer():\n",
    "    vec = CountVectorizer(binary=True, max_features=10000)\n",
    "    x_train = vec.fit_transform(train['text']).toarray()\n",
    "    x_test = vec.transform(test['text']).toarray()\n",
    "    return x_train, x_test\n",
    "\n",
    "# Model definition\n",
    "class SentimentMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=100, output_dim=3):\n",
    "        super(SentimentMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0602d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(x_train, x_test, y_train, y_test, epochs):\n",
    "    results = []\n",
    "    X_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    for epoch_count in epochs:\n",
    "        model = SentimentMLP(input_dim=x_train.shape[1])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(epoch_count), desc=f\"Training {epoch_count} epochs\"):\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_test_tensor)\n",
    "            predicted = torch.argmax(preds, dim=1).numpy()\n",
    "            precision = precision_score(y_test, predicted, average='macro')\n",
    "            recall = recall_score(y_test, predicted, average='macro')\n",
    "            f1 = f1_score(y_test, predicted, average='macro')\n",
    "            results.append((epoch_count, precision, recall, f1))\n",
    "    return results\n",
    "\n",
    "# Run for each vectorizer\n",
    "vectorizer_functions = {\n",
    "    'TFIDF': tfidf_vectorizer,\n",
    "    'BoG': bog_vectorizer,\n",
    "    'Binary': binary_vectorizer\n",
    "}\n",
    "epoch_settings = [5, 10, 20, 50]\n",
    "all_results = []\n",
    "\n",
    "for name, func in tqdm(vectorizer_functions.items(), desc=\"Vectorizers\"):\n",
    "    x_train_vec, x_test_vec = func()\n",
    "    results = train_and_evaluate(x_train_vec, x_test_vec, y_train, y_test, epoch_settings)\n",
    "    for epoch, precision, recall, f1 in results:\n",
    "        all_results.append({\n",
    "            'Vectorizer': name,\n",
    "            'Epochs': epoch,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "df_results = pd.DataFrame(all_results)\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "df_results.to_csv(\"outputs/nn.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194ed40",
   "metadata": {},
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def inference(text_list, model_weights_path=\"weights/binary_mlp.pt\"):\n",
    "    # Recreate vectorizer and fit again (same as training time)\n",
    "    train = pd.read_csv('data/processed_train.csv')\n",
    "    label_encoder = LabelEncoder().fit(train['sentiment'])\n",
    "    vectorizer = CountVectorizer(binary=True, max_features=10000)\n",
    "    vectorizer.fit(train['text'])\n",
    "\n",
    "    x_input = vectorizer.transform(text_list).toarray()\n",
    "    x_tensor = torch.tensor(x_input, dtype=torch.float32)\n",
    "\n",
    "    # Load model and weights\n",
    "    model = SentimentMLP(input_dim=x_input.shape[1])\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x_tensor)\n",
    "        preds = torch.argmax(outputs, dim=1).numpy()\n",
    "    return label_encoder.inverse_transform(preds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    examples = [\"I love this movie!\", \"Worst experience ever.\"]\n",
    "    predictions = inference(examples)\n",
    "    for text, pred in zip(examples, predictions):\n",
    "        print(f\"Text: {text}\\nPredicted Sentiment: {pred}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
