{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b344f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86674206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label(num):\n",
    "    if num == 0:\n",
    "        return 'negative'\n",
    "    elif num == 1:\n",
    "        return 'neutral'\n",
    "    elif num == 2:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca159349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/processed_train.csv')\n",
    "tfidf_vec = TfidfVectorizer(max_features=10000).fit(train['text'])\n",
    "bog_vec = CountVectorizer(max_features=10000).fit(train['text'])\n",
    "binary_vec = CountVectorizer(max_features=10000, binary=True).fit(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792fa5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_model = joblib.load('weights/k_means.pkl')\n",
    "random_forest_model = joblib.load('weights/random_forest.pkl')\n",
    "logistic_model = joblib.load('weights/logistic_regression.pkl')\n",
    "with gzip.open(\"weights/knn.pkl.gz\", \"rb\") as f:\n",
    "    knn_model = joblib.load(f)\n",
    "with gzip.open(\"weights/svm.pkl.gz\", \"rb\") as f:\n",
    "    svm_model = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "547eafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Dropout,Dense,LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=256, input_length= 24))  # Input layer\n",
    "model.add(LSTM(256, return_sequences=True))  # First LSTM layer, returns sequences\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(LSTM(128, return_sequences=True))  # Second LSTM layer, does not return sequences by default\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.load_weights('weights/lstm.h5')\n",
    "lstm_model = model\n",
    "\n",
    "\n",
    "\n",
    "total_word=10000\n",
    "token=Tokenizer(num_words=total_word)\n",
    "token.fit_on_texts(train['text'])\n",
    "sequences=token.texts_to_sequences(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebf2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, text):\n",
    "    if model == 'knn':\n",
    "        x_predict = tfidf_vec.transform([text]).toarray()\n",
    "        sentiment = transform_label(knn_model.predict(x_predict))\n",
    "    elif model == 'random_forest':\n",
    "        x_predict = bog_vec.transform([text]).toarray()\n",
    "        sentiment = transform_label(random_forest_model.predict(x_predict))\n",
    "    elif model == 'logistic_regression':\n",
    "        x_predict = bog_vec.transform([text]).toarray()\n",
    "        sentiment = transform_label(logistic_model.predict(x_predict))\n",
    "    elif model == 'svm':\n",
    "        x_predict = tfidf_vec.transform([text]).toarray()\n",
    "        sentiment = transform_label(svm_model.predict(x_predict))\n",
    "    elif model == 'kmeans':\n",
    "        x_predict = tfidf_vec.transform([text]).toarray()\n",
    "        sentiment = transform_label(k_means_model.predict(x_predict))\n",
    "    elif model == 'lstm':\n",
    "        new_reviews=[]\n",
    "        new_reviews.append(text)\n",
    "        new_reviews_seq = token.texts_to_sequences(new_reviews)\n",
    "        new_reviews_padded = pad_sequences(new_reviews_seq, maxlen=24)\n",
    "\n",
    "        predictions = lstm_model.predict(new_reviews_padded, verbose=0)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        sentiment = transform_label(predicted_classes[0])\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7fcde14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[664, 7, 2410, 694]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0  664    7 2410  694]]\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(inference('lstm', \"I absolutely love this product! It's fantastic!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa0099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
